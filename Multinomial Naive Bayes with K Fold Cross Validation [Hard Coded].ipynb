{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-Validation\n",
    "Idea: Split the data into k sections or 'folds'. The model runs k times. Each fold is used once as validation while the others form the training set. The accuracy is the average of all the tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#Split\n",
    "result = pd.read_csv(\"balanced_dataset.csv\")\n",
    "X = result['review']\n",
    "y = result['label']\n",
    "\n",
    "SPLITS = 3\n",
    "kf = KFold(n_splits=SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "counter = 0\n",
    "\n",
    "for i in range(1, SPLITS+1):\n",
    "    if(os.path.isdir(\"SPLIT_\" + str(i)) == False):\n",
    "        os.mkdir(\"SPLIT_\"  + str(i))\n",
    "\n",
    "for train_ind, test_ind in kf.split(X):\n",
    "    train_df = result.iloc[train_ind, :]\n",
    "    test_df = result.iloc[test_ind, :]\n",
    "    counter = 1 + counter\n",
    "    #Print to the training set\n",
    "    train_df.to_csv('SPLIT_' + str(counter) + '/train.csv', encoding='utf-8', index=False)\n",
    "    #Print the validation to the test set\n",
    "    test_df.to_csv('SPLIT_' + str(counter) + '/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training the classifier, we need to declare the list of stop words we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a list with words that we may encounter in the reviews that just add noise to our classifier\n",
    "#E.g.: pronouns, articles, quantifiers, etc.\n",
    "stop_words = [\"you\", \"your\", \"got\", \"she\", \"they\", \"him\", \"her\", \"them\", \"what\", \"where\", \"who\", \"have\", \"does\",\n",
    "              \"whom\", \"mine\", \"yours\", \"his\", \"hers\", \"ours\", \"theirs\", \"this\", \"that\", \"these\", \"those\", \"did\", \n",
    "              \"there\", \"about\", \"which\", \"whose\", \"whoever\", \"whatever\", \"whichever\", \"whomever\", \"wherever\", \n",
    "              \"myself\", \"yourself\", \"because\", \"for\", \"himself\", \"herself\", \"itself\", \"ourselves\", \"themselves\", \n",
    "              \"anything\", \"everybody\", \"another\", \"each\", \"few\", \"many\", \"none\", \"some\", \"all\", \"any\", \"it\", \"our\",   \n",
    "              \"anybody\", \"anyone\", \"everyone\", \"everything\", \"nobody\", \"other\", \"others\", \"somebody\", \"someone\", \n",
    "              \"something\", \"one\", \"the\", \"before\", \"after\", \"through\", \"just\", \"could\", \"but\", \"however\", \"how\", \n",
    "              \"can\", \"could\", \"with\", \"went\", \"are\", \"were\", \"was\", \"and\", \"from\", \"would\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train the Classifier & Perform the Prediction\n",
    "\n",
    "Training: Create a dictionary using all the words that appear in the reviews in train.csv then find how many times each word appears in positive, negative, and neutral reviews. Create a file dictionary.csv with the stats.\n",
    "\n",
    "Predicting: We classify every record in test.csv as either positive (1), negative (-1), or neutral (0) using a supervised naive-Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter in range(1, SPLITS+1):\n",
    "    #Create a dictionary with all the words that appear in the reviews\n",
    "    df = pd.DataFrame()\n",
    "    print(\"Processing train and test files for SPLIT =\", counter)\n",
    "    print(\"Please allow for a sufficient amount of time (30 to 35 hrs) to train the classifier and run the model to predict test.csv.\")\n",
    "    with open('SPLIT_' + str(counter) + '/train.csv', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        counter_negative_reviews = 0\n",
    "        counter_positive_reviews = 0\n",
    "        counter_neutral_reviews = 0\n",
    "        #Read every line\n",
    "        for row in reader:\n",
    "            review = len(row) - 2 #Position of the review column\n",
    "            label = len(row) - 1 #Position of the label column\n",
    "            #Skip the first row\n",
    "            if(row[review] != \"review\"):\n",
    "                if(row[label] == \"1\"):\n",
    "                    counter_positive_reviews = counter_positive_reviews + 1\n",
    "                elif(row[label] == \"0\"):\n",
    "                    counter_neutral_reviews = counter_neutral_reviews + 1\n",
    "                elif(row[label] == \"-1\"):\n",
    "                    counter_negative_reviews = counter_negative_reviews + 1                \n",
    "                print(\"Creating dictionary. Currently working on line with bookID\", row[0])\n",
    "                #Tokenize the review into words and store them in a list \n",
    "                list = row[review].split()\n",
    "                #For each word in the list\n",
    "                for i in range(0, len(list)):\n",
    "                    word = list[i].lower().strip()\n",
    "                    #That is not an article, pronoun or preposition and that is not in stop_words\n",
    "                    if((word not in stop_words) and (len(word) > 2)):\n",
    "                        #Find its label\n",
    "                        review_type = \"\"\n",
    "                        if(row[label] == \"1\"):\n",
    "                            review_type = \"positive\"\n",
    "                        elif(row[label] == \"0\"):\n",
    "                            review_type = \"neutral\"\n",
    "                        else:\n",
    "                            review_type = \"negative\"\n",
    "                        #If that word is already in the dataframe update the label count\n",
    "                        if(len(df) > 0 and len(df[df.word == word]) == 1):\n",
    "                            df.loc[df.word == word, review_type] = 1 + df.loc[df.word == word, review_type]\n",
    "                        #If not then create it\n",
    "                        else:\n",
    "                            if(review_type == \"positive\"):\n",
    "                                df = df.append({'word': word, 'positive': 1, 'negative': 0, 'neutral': 0}, ignore_index=True) \n",
    "                            elif(review_type == \"neutral\"):\n",
    "                                df = df.append({'word': word, 'positive': 0, 'negative': 0, 'neutral': 1}, ignore_index=True)\n",
    "                            else:\n",
    "                                df = df.append({'word': word, 'positive': 0, 'negative': 1, 'neutral': 0}, ignore_index=True)\n",
    "\n",
    "    #print(df) \n",
    "    #Place our new lexicon in a csv file\n",
    "    df.to_csv('SPLIT_' + str(counter) + '/dictionary.csv', index=False)  \n",
    "    counter_total_reviews = counter_positive_reviews + counter_negative_reviews + counter_neutral_reviews\n",
    "    print(\"Total number of positive reviews:\", counter_positive_reviews)\n",
    "    print(\"Total number of negative reviews:\", counter_negative_reviews)\n",
    "    print(\"Total number of neutral reviews:\", counter_neutral_reviews)\n",
    "    print(\"Total number of reviews:\", counter_total_reviews)\n",
    "    with open('SPLIT_' + str(counter) + '/prediction.csv', \"w\") as w:\n",
    "        with open('SPLIT_' + str(counter) + '/test.csv', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)            \n",
    "            #Read every line\n",
    "            for row in reader:\n",
    "                #Check if you are working with the first line so you can add a new column, \"NB_predictedLabel\" to the new file prediction.csv\n",
    "                if(row[0] == \"bookID\"):\n",
    "                    row.append(\"NB_predictedLabel\")\n",
    "                    w.write(\",\".join(row))\n",
    "                    w.write(\"\\n\")\n",
    "                else: \n",
    "                    #1. Copy the whole row into prediction.csv\n",
    "                    for i in range(0, len(row)):\n",
    "                        w.write(row[i])\n",
    "                        w.write(\",\")\n",
    "                    #2. Build the model and perform the prediction     \n",
    "                    #Continue reading from test.csv\n",
    "                    review = len(row) - 2 #Position of the review column in test.csv\n",
    "                    label = len(row) - 1 #Position of the label column in test.csv\n",
    "                    print(\"Predicting the review type of row with bookID\", row[0])                                \n",
    "                    #Tokenize the review into words and store them in a list \n",
    "                    list = row[review].split()\n",
    "                    #Calculate the general probability that a new review has of belonging to each of the 3 classes [this calculation is based on the train.csv file]\n",
    "                    probability_positive = counter_positive_reviews/counter_total_reviews #P(Positive)\n",
    "                    probability_negative = counter_negative_reviews/counter_total_reviews #P(Negative)\n",
    "                    probability_neutral = counter_neutral_reviews/counter_total_reviews #P(Neutral)   \n",
    "                    #For each word in the list\n",
    "                    for i in range(0, len(list)):\n",
    "                        word = list[i].lower().strip()\n",
    "                        #That is not an article, pronoun or preposition and that is not in stop_words\n",
    "                        if((word not in stop_words) and (len(word) > 2)):\n",
    "                            #Predict the conditional likelihood probability that this word has of appearing in each of the 3 classes: positive, negative and neutral [based on train.csv and the lexicon]\n",
    "                            #1. The word is in lexicon\n",
    "                            if(len(df[df.word == word]) == 1):\n",
    "                                #Calculate P(word|positive)\n",
    "                                p = (int(df.loc[df.word == word, \"positive\"]) + 1)/(sum(df[\"positive\"].tolist()) + len(df))\n",
    "                                probability_positive = p * probability_positive\n",
    "                                #Calculate P(word|negative)\n",
    "                                p = (int(df.loc[df.word == word, \"negative\"]) + 1)/(sum(df[\"negative\"].tolist()) + len(df))\n",
    "                                probability_negative = p * probability_negative\n",
    "                                #Calculate P(word|neutral)\n",
    "                                p = (int(df.loc[df.word == word, \"neutral\"]) + 1)/(sum(df[\"neutral\"].tolist()) + len(df))\n",
    "                                probability_neutral = p * probability_neutral\n",
    "                            #2. The word is not in the lexicon\n",
    "                            else:\n",
    "                                #Calculate P(word|positive)\n",
    "                                p = (1)/(sum(df[\"positive\"].tolist()) + len(df))\n",
    "                                probability_positive = p * probability_positive\n",
    "                                #Calculate P(word|negative)\n",
    "                                p = (1)/(sum(df[\"negative\"].tolist()) + len(df))\n",
    "                                probability_negative = p * probability_negative\n",
    "                                #Calculate P(word|neutral)\n",
    "                                p = (1)/(sum(df[\"neutral\"].tolist()) + len(df))\n",
    "                                probability_neutral = p * probability_neutral \n",
    "                    #3. Copy the prediction into the last column of the row\n",
    "                    if(probability_positive > probability_negative and probability_positive > probability_neutral):\n",
    "                        w.write(\"1\")\n",
    "                    elif(probability_neutral > probability_negative and probability_neutral > probability_positive):\n",
    "                        w.write(\"0\")\n",
    "                    elif(probability_negative > probability_neutral and probability_negative > probability_positive):\n",
    "                        w.write(\"-1\")\n",
    "                    else: #When there are two or three classes with the same probability\n",
    "                        w.write(\"N/A\")        \n",
    "                    w.write(\"\\n\")\n",
    "    print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "SPLITS = 3\n",
    "\n",
    "for counter in range(1, SPLITS+1):\n",
    "    correct_predictions = 0\n",
    "    incorrect_predictions = 0\n",
    "    with open('SPLIT_' + str(counter) + '/prediction.csv', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        #Read every line\n",
    "        for row in reader:\n",
    "            label = len(row) - 2 \n",
    "            predicted_label = len(row) - 1 \n",
    "            if(row[0] != \"bookID\"):            \n",
    "                if(row[label] == row[predicted_label]):\n",
    "                    correct_predictions = 1 + correct_predictions\n",
    "                else:\n",
    "                    incorrect_predictions = 1 + incorrect_predictions\n",
    "print(\"Classifier Accuracy:\", correct_predictions/(correct_predictions + incorrect_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
